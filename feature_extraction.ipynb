{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sets(data):\n",
    "    essay_sets = []\n",
    "    min_scores = []\n",
    "    max_scores = []\n",
    "    for s in range(1,9):\n",
    "        essay_set = data[data[\"essay_set\"] == s]\n",
    "        essay_set.dropna(axis=1, inplace=True)\n",
    "        n, d = essay_set.shape\n",
    "        set_scores = essay_set[\"domain1_score\"]\n",
    "        print (\"Set\", s, \": Essays = \", n , \"\\t Attributes = \", d)\n",
    "        min_scores.append(set_scores.min())\n",
    "        max_scores.append(set_scores.max())\n",
    "        essay_sets.append(essay_set)\n",
    "    return (essay_sets, min_scores, max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Set 1 : Essays =  1783 \t Attributes =  6\nSet 2 : Essays =  1800 \t Attributes =  9\nSet 3 : Essays =  1726 \t Attributes =  6\nSet 4 : Essays =  1770 \t Attributes =  6\nSet 5 : Essays =  1805 \t Attributes =  6\nSet 6 : Essays =  1800 \t Attributes =  6\nSet 7 : Essays =  1569 \t Attributes =  14\nSet 8 : Essays =  723 \t Attributes =  18\nAll Data: 12976\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   essay_id  essay_set                                              essay  \\\n0         1          1  Dear local newspaper, I think effects computer...   \n1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n4         5          1  Dear @LOCATION1, I know having computers has a...   \n\n   domain1_score  \n0              8  \n1              9  \n2              7  \n3             10  \n4              8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>essay_set</th>\n      <th>essay</th>\n      <th>domain1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Dear local newspaper, I think effects computer...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Dear @LOCATION1, I know having computers has a...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "dataset_path = \"./asap-aes/training_set_rel3.tsv\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "min_scores = [2, 1, 0, 0, 0, 0, 0, 0]\n",
    "max_scores = [12, 6, 3, 3, 4, 4, 30, 60]\n",
    "\n",
    "essay_sets, data_min_scores, data_max_scores = split_in_sets(data)\n",
    "set1, set2, set3, set4, set5, set6, set7, set8 = tuple(essay_sets)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "\n",
    "data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n",
    "print(\"All Data:\", len(data))\n",
    "data.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Minimum Scores:  [2, 1, 0, 0, 0, 0, 0, 0]\nMaximum Scores:  [12, 6, 3, 3, 4, 4, 30, 60]\n"
    }
   ],
   "source": [
    "print(\"Minimum Scores: \", min_scores)\n",
    "print(\"Maximum Scores: \", max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset keys\n",
    "essay_id_key = \"essay_id\"\n",
    "essay_set_key = \"essay_set\"\n",
    "essay_key = \"essay\"\n",
    "domain1_score_key = \"domain1_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature keys\n",
    "feature_keys = {\n",
    "    \"char_count_key\": \"char_count\",\n",
    "    \"word_count_key\": \"word_count\",\n",
    "    \"diff_words_count_key\": \"diff_words_count\",\n",
    "    \"word_count_root_key\": \"word_count_root\",\n",
    "    \"sen_count_key\": \"sen_count\",\n",
    "    \"avg_word_len_key\": \"avg_word_len\",\n",
    "    \"avg_sen_len_key\": \"avg_sen_len\",\n",
    "    \"l5_word_count_key\": \"l5_word_count\",\n",
    "    \"l6_word_count_key\": \"l6_word_count\",\n",
    "    \"l7_word_count_key\": \"l7_word_count\",\n",
    "    \"l8_word_count_key\": \"l8_word_count\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra features\n",
    "extra_feature_keys = {\n",
    "    # \"grammer_error_count_key\": \"grammer_error_count\",\n",
    "    \"spelling_error_count_key\": \"spelling_error_count\",\n",
    "    \"stopwords_count_key\": \"stopwords_count\",\n",
    "    \"small_sentences_count_key\": \"small_sentence_count\", #sentences less than len 4\n",
    "    # \"beautiful_words_count_key\": \"beautiful_words_count\",\n",
    "    \"punctuations_count_key\": \"punctuations_count\",\n",
    "    \"verbs_count_key\": \"verbs_count\",\n",
    "    \"adverbs_count_key\": \"adverbs_count\",\n",
    "    \"nouns_count_key\": \"nouns_count\",\n",
    "    \"adjectives_count_key\": \"adjective_count\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Basic 11 features:  ['char_count', 'word_count', 'diff_words_count', 'word_count_root', 'sen_count', 'avg_word_len', 'avg_sen_len', 'l5_word_count', 'l6_word_count', 'l7_word_count', 'l8_word_count'] \n\nExtra features:  ['spelling_error_count', 'stopwords_count', 'small_sentence_count', 'punctuations_count', 'verbs_count', 'adverbs_count', 'nouns_count', 'adjective_count'] \n\nAll features:  ['char_count', 'word_count', 'diff_words_count', 'word_count_root', 'sen_count', 'avg_word_len', 'avg_sen_len', 'l5_word_count', 'l6_word_count', 'l7_word_count', 'l8_word_count', 'spelling_error_count', 'stopwords_count', 'small_sentence_count', 'punctuations_count', 'verbs_count', 'adverbs_count', 'nouns_count', 'adjective_count'] \n\n"
    }
   ],
   "source": [
    "feature_keys_list = list(feature_keys.values())\n",
    "extra_feature_keys_list = list(extra_feature_keys.values())\n",
    "all_feature_keys_list = feature_keys_list + extra_feature_keys_list\n",
    "\n",
    "print(\"Basic 11 features: \", feature_keys_list, \"\\n\")\n",
    "print(\"Extra features: \", extra_feature_keys_list, \"\\n\")\n",
    "print(\"All features: \", all_feature_keys_list, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hapenning\n"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "misspelled = spell.unknown(['something', 'is', 'hapenning', 'here'])\n",
    "for word in misspelled:\n",
    "    print(word)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import language_check\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "tagger=PerceptronTagger() # load outside\n",
    "tool = language_check.LanguageTool('en-US')\n",
    "spell = SpellChecker()\n",
    "spell.word_frequency.load_words([\"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"DATE\", \"TIME\", \"MONEY\", \"PERCENT\", \"CAPS\"])\n",
    "\n",
    "def sentence_to_word_list(sentence, remove_stopwords):\n",
    "    # Remove non letter from sentenece and stop words\n",
    "    sen_char_count = 0\n",
    "    sen_word_count = 0\n",
    "    l5_sen_word_count = 0\n",
    "    l6_sen_word_count = 0\n",
    "    l7_sen_word_count = 0\n",
    "    l8_sen_word_count = 0    \n",
    "    sen_diff_words = set()\n",
    "    ### Extra Features ###\n",
    "    sen_verbs_count = 0\n",
    "    sen_adverbs_count = 0\n",
    "    sen_nouns_count = 0\n",
    "    sen_adjectives_count = 0\n",
    "    sen_spelling_error_count = 0\n",
    "    sen_stopwords_count = 0\n",
    "    is_small_sentence = 0\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    all_words = sentence.lower().split()\n",
    "\n",
    "    # count= Counter([j for i,j in tagger.tag(all_words)])\n",
    "    # sen_verbs_count = count['VB'] + count['VBG'] + count['VBP'] + count['VBN'] + count['VBZ']\n",
    "    # sen_adverbs_count = count['RB'] + count['RBR'] + count['RBS']\n",
    "    # sen_nouns_count = count['NN'] + count['NNS'] + count['NNPS'] + count['NNP']\n",
    "    # sen_adjectives_count = count['JJ'] + count['JJR'] \n",
    "\n",
    "    kept_words = []\n",
    "\n",
    "\n",
    "    if len(all_words) <= 4: is_small_sentence = 1\n",
    "\n",
    "    \n",
    "    misspelled = spell.unknown(all_words)\n",
    "    sen_spelling_error_count = len(misspelled)\n",
    "\n",
    "    for word in all_words:\n",
    "        sen_char_count += len(word)\n",
    "        sen_word_count += 1\n",
    "        word_len = len(word)\n",
    "        if word_len > 5:\n",
    "            l5_sen_word_count += 1\n",
    "        if word_len > 6:\n",
    "            l6_sen_word_count += 1\n",
    "        if word_len > 7:\n",
    "            l7_sen_word_count += 1\n",
    "        if word_len > 8:\n",
    "            l8_sen_word_count += 1\n",
    "\n",
    "        sen_diff_words.add(word)\n",
    "\n",
    "        isStopword = word in stops\n",
    "        if isStopword: sen_stopwords_count += 1\n",
    "\n",
    "        if remove_stopwords and not isStopword:\n",
    "            kept_words.append(word)\n",
    "        else:\n",
    "            kept_words.append(word)\n",
    "\n",
    "    features = {\n",
    "         feature_keys[\"char_count_key\"]: sen_char_count,\n",
    "         feature_keys[\"word_count_key\"]: sen_word_count,\n",
    "         feature_keys[\"l5_word_count_key\"]: l5_sen_word_count,\n",
    "         feature_keys[\"l6_word_count_key\"]: l6_sen_word_count,\n",
    "         feature_keys[\"l7_word_count_key\"]: l7_sen_word_count,\n",
    "         feature_keys[\"l8_word_count_key\"]: l8_sen_word_count,\n",
    "         feature_keys[\"diff_words_count_key\"]: sen_diff_words\n",
    "    }\n",
    "\n",
    "    extra_features = {\n",
    "        extra_feature_keys[\"small_sentences_count_key\"]: is_small_sentence,\n",
    "        extra_feature_keys[\"spelling_error_count_key\"]: sen_spelling_error_count,\n",
    "        extra_feature_keys[\"stopwords_count_key\"]: sen_stopwords_count,\n",
    "        extra_feature_keys[\"verbs_count_key\"]: sen_verbs_count,\n",
    "        extra_feature_keys[\"adverbs_count_key\"]: sen_adverbs_count,\n",
    "        extra_feature_keys[\"nouns_count_key\"]: sen_nouns_count,\n",
    "        extra_feature_keys[\"adjectives_count_key\"]: sen_adjectives_count,\n",
    "    }\n",
    "\n",
    "    return (kept_words, features, extra_features)\n",
    "\n",
    "def essay_to_sentences(essay, remove_stopwords = False):\n",
    "    # Convert essay into sentence\n",
    "    \n",
    "\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(essay.strip())\n",
    "    split_sentences = []\n",
    "\n",
    "    char_count = 0\n",
    "    word_count = 0\n",
    "    diff_words = set()\n",
    "    word_count_root = 0\n",
    "    sen_count = 0\n",
    "    avg_word_len = 0\n",
    "    avg_sen_len = 0\n",
    "    l5_word_count = 0\n",
    "    l6_word_count = 0\n",
    "    l7_word_count = 0\n",
    "    l8_word_count = 0    \n",
    "    \n",
    "\n",
    "    ### Extra Features ###\n",
    "    spelling_error_count = 0\n",
    "    stopwords_count = 0\n",
    "    small_sentences_count = 0\n",
    "    punctuation_count = 0\n",
    "    grammer_error_count = 0\n",
    "    small_sentences_count = 0\n",
    "    verbs_count = 0\n",
    "    adverbs_count = 0\n",
    "    nouns_count = 0\n",
    "    adjectives_count = 0\n",
    " \n",
    "    all_words = nltk.word_tokenize(essay)\n",
    "    count= Counter([j for i,j in tagger.tag(all_words)])\n",
    "    verbs_count = count['VB'] + count['VBG'] + count['VBP'] + count['VBN'] + count['VBZ']\n",
    "    adverbs_count = count['RB'] + count['RBR'] + count['RBS']\n",
    "    nouns_count = count['NN'] + count['NNS'] + count['NNPS'] + count['NNP']\n",
    "    adjectives_count = count['JJ'] + count['JJR'] \n",
    "\n",
    "    punctuation = ['.','?', '!', ':', ';']\n",
    "    for punct in punctuation:\n",
    "        punctuation_count += essay.count(punct)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "            # grammer_error_count += len(tool.check(sentence))\n",
    "            \n",
    "\n",
    "            kept_words, features, extra_features = sentence_to_word_list(sentence, remove_stopwords)\n",
    "            split_sentences.append(kept_words)\n",
    "            \n",
    "            sen_count +=1\n",
    "            char_count += features[feature_keys[\"char_count_key\"]]\n",
    "            word_count += features[feature_keys[\"word_count_key\"]]\n",
    "            l5_word_count += features[feature_keys[\"l5_word_count_key\"]]\n",
    "            l6_word_count += features[feature_keys[\"l6_word_count_key\"]]\n",
    "            l7_word_count += features[feature_keys[\"l7_word_count_key\"]]\n",
    "            l8_word_count += features[feature_keys[\"l8_word_count_key\"]]\n",
    "            diff_words = diff_words|features[feature_keys[\"diff_words_count_key\"]]\n",
    "            ### Extra Features ###\n",
    "            spelling_error_count += extra_features[extra_feature_keys[\"spelling_error_count_key\"]]\n",
    "            stopwords_count += extra_features[extra_feature_keys[\"stopwords_count_key\"]]\n",
    "            small_sentences_count += extra_features[extra_feature_keys[\"small_sentences_count_key\"]]\n",
    "            # verbs_count += extra_features[extra_feature_keys[\"verbs_count_key\"]]\n",
    "            # adverbs_count += extra_features[extra_feature_keys[\"adjectives_count_key\"]]\n",
    "            # nouns_count += extra_features[extra_feature_keys[\"nouns_count_key\"]]\n",
    "            # adjectives_count += extra_features[extra_feature_keys[\"adjectives_count_key\"]]\n",
    "\n",
    "\n",
    "    word_count_root = word_count ** (1/4)\n",
    "    avg_word_len = char_count / word_count\n",
    "    avg_sen_len = word_count / sen_count\n",
    "\n",
    "    features = {\n",
    "        feature_keys[\"char_count_key\"]: char_count,\n",
    "        feature_keys[\"word_count_key\"]: word_count,\n",
    "        feature_keys[\"diff_words_count_key\"]: len(diff_words),\n",
    "        feature_keys[\"word_count_root_key\"]: word_count_root,\n",
    "        feature_keys[\"sen_count_key\"]: sen_count,\n",
    "        feature_keys[\"avg_word_len_key\"]: avg_word_len,\n",
    "        feature_keys[\"avg_sen_len_key\"]: avg_sen_len,\n",
    "        feature_keys[\"l5_word_count_key\"]: l5_word_count,\n",
    "        feature_keys[\"l6_word_count_key\"]: l6_word_count,\n",
    "        feature_keys[\"l7_word_count_key\"]: l7_word_count,\n",
    "        feature_keys[\"l8_word_count_key\"]: l8_word_count\n",
    "    }\n",
    "\n",
    "    extra_features = {\n",
    "        # extra_feature_keys[\"grammer_error_count_key\"]: grammer_error_count,\n",
    "        extra_feature_keys[\"spelling_error_count_key\"]: spelling_error_count,\n",
    "        extra_feature_keys[\"stopwords_count_key\"]: stopwords_count,\n",
    "        extra_feature_keys[\"small_sentences_count_key\"]: small_sentences_count,\n",
    "        extra_feature_keys[\"punctuations_count_key\"]: punctuation_count,\n",
    "        extra_feature_keys[\"verbs_count_key\"]: verbs_count,\n",
    "        extra_feature_keys[\"adverbs_count_key\"]: adverbs_count,\n",
    "        extra_feature_keys[\"nouns_count_key\"]: nouns_count,\n",
    "        extra_feature_keys[\"adjectives_count_key\"]: adjectives_count\n",
    "    }\n",
    "\n",
    "    return (split_sentences, features, extra_features)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\nExecution time: 0.04050278663635254\n\n\nFeatures: \n{   'avg_sen_len': 21.875,\n    'avg_word_len': 4.222857142857142,\n    'char_count': 1478,\n    'diff_words_count': 164,\n    'l5_word_count': 74,\n    'l6_word_count': 59,\n    'l7_word_count': 34,\n    'l8_word_count': 13,\n    'sen_count': 16,\n    'word_count': 350,\n    'word_count_root': 4.3253077270721105}\n\n\n Extra Features: \n{   'adjective_count': 22,\n    'adverbs_count': 21,\n    'nouns_count': 84,\n    'punctuations_count': 17,\n    'small_sentence_count': 3,\n    'spelling_error_count': 9,\n    'stopwords_count': 184,\n    'verbs_count': 67}\n"
    }
   ],
   "source": [
    "import pprint\n",
    "from time import time \n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "#Featrues\n",
    "first_essay = data.iloc[0][essay_key]\n",
    "print(first_essay)\n",
    "start = time()\n",
    "split_sentences, features, extra_features = essay_to_sentences(first_essay)\n",
    "end = time()\n",
    "print(\"Execution time:\", end-start)\n",
    "# print(split_sentences)\n",
    "print(\"\\n\\nFeatures: \")\n",
    "pp.pprint(features)\n",
    "\n",
    "print(\"\\n\\n Extra Features: \")\n",
    "pp.pprint(extra_features)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def makeDataFrame(data):\n",
    "    all_features = {}\n",
    "    all_scores = {}\n",
    "\n",
    "\n",
    "    for row in range(len(data)):\n",
    "        # if row % 500 == 0: print(\"Processed \", row, \" essays of\", len(data), \" rows.\")\n",
    "        essay_data = data.iloc[row]\n",
    "        essay = essay_data[essay_key]\n",
    "        essay_id = essay_data[essay_id_key]\n",
    "        essay_score = essay_data[domain1_score_key]\n",
    "        _, features, extra_features = essay_to_sentences(essay)\n",
    "\n",
    "        combined_features = {}\n",
    "        combined_features.update(features)\n",
    "        combined_features.update(extra_features)\n",
    "        all_features[essay_id] = combined_features\n",
    "        all_scores[essay_id] = essay_score\n",
    "\n",
    "    X = pd.DataFrame.from_dict(all_features, orient=\"index\")\n",
    "    y = pd.DataFrame.from_dict(all_scores, orient=\"index\")\n",
    "\n",
    "    return(X, y)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Processed  0  essays of 12976  rows.\nProcessed  500  essays of 12976  rows.\nProcessed  1000  essays of 12976  rows.\nProcessed  1500  essays of 12976  rows.\nProcessed  2000  essays of 12976  rows.\nProcessed  2500  essays of 12976  rows.\nProcessed  3000  essays of 12976  rows.\nProcessed  3500  essays of 12976  rows.\nProcessed  4000  essays of 12976  rows.\nProcessed  4500  essays of 12976  rows.\nProcessed  5000  essays of 12976  rows.\nProcessed  5500  essays of 12976  rows.\nProcessed  6000  essays of 12976  rows.\nProcessed  6500  essays of 12976  rows.\nProcessed  7000  essays of 12976  rows.\nProcessed  7500  essays of 12976  rows.\nProcessed  8000  essays of 12976  rows.\nProcessed  8500  essays of 12976  rows.\nProcessed  9000  essays of 12976  rows.\nProcessed  9500  essays of 12976  rows.\nProcessed  10000  essays of 12976  rows.\nProcessed  10500  essays of 12976  rows.\nProcessed  11000  essays of 12976  rows.\nProcessed  11500  essays of 12976  rows.\nProcessed  12000  essays of 12976  rows.\nProcessed  12500  essays of 12976  rows.\nExecution time to make dataframe:  269.11509823799133\n"
    }
   ],
   "source": [
    "from time import time \n",
    "start = time()\n",
    "X, y = makeDataFrame(data)\n",
    "end = time()\n",
    "print(\"Execution time to make dataframe: \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12976\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   char_count  word_count  diff_words_count  word_count_root  sen_count  \\\n1        1478         350               164         4.325308         16   \n2        1814         423               192         4.535081         20   \n3        1222         283               147         4.101537         14   \n4        2510         530               232         4.798096         27   \n5        2046         473               200         4.663535         30   \n\n   avg_word_len  avg_sen_len  l5_word_count  l6_word_count  l7_word_count  \\\n1      4.222857    21.875000             74             59             34   \n2      4.288416    21.150000            106             80             53   \n3      4.318021    20.214286             78             53             32   \n4      4.735849    19.629630            169            128             84   \n5      4.325581    15.766667            128             87             57   \n\n   l8_word_count  spelling_error_count  stopwords_count  small_sentence_count  \\\n1             13                     9              184                     3   \n2             26                    17              199                     0   \n3             19                     2              147                     1   \n4             52                    27              228                     1   \n5             34                    11              249                     0   \n\n   punctuations_count  verbs_count  adverbs_count  nouns_count  \\\n1                  17           67             21           84   \n2                  20           77             18          114   \n3                  14           52             14           86   \n4                  27           82             28          197   \n5                  30           85             36          116   \n\n   adjective_count  \n1               22  \n2               20  \n3               18  \n4               46  \n5               31  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>diff_words_count</th>\n      <th>word_count_root</th>\n      <th>sen_count</th>\n      <th>avg_word_len</th>\n      <th>avg_sen_len</th>\n      <th>l5_word_count</th>\n      <th>l6_word_count</th>\n      <th>l7_word_count</th>\n      <th>l8_word_count</th>\n      <th>spelling_error_count</th>\n      <th>stopwords_count</th>\n      <th>small_sentence_count</th>\n      <th>punctuations_count</th>\n      <th>verbs_count</th>\n      <th>adverbs_count</th>\n      <th>nouns_count</th>\n      <th>adjective_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1478</td>\n      <td>350</td>\n      <td>164</td>\n      <td>4.325308</td>\n      <td>16</td>\n      <td>4.222857</td>\n      <td>21.875000</td>\n      <td>74</td>\n      <td>59</td>\n      <td>34</td>\n      <td>13</td>\n      <td>9</td>\n      <td>184</td>\n      <td>3</td>\n      <td>17</td>\n      <td>67</td>\n      <td>21</td>\n      <td>84</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1814</td>\n      <td>423</td>\n      <td>192</td>\n      <td>4.535081</td>\n      <td>20</td>\n      <td>4.288416</td>\n      <td>21.150000</td>\n      <td>106</td>\n      <td>80</td>\n      <td>53</td>\n      <td>26</td>\n      <td>17</td>\n      <td>199</td>\n      <td>0</td>\n      <td>20</td>\n      <td>77</td>\n      <td>18</td>\n      <td>114</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1222</td>\n      <td>283</td>\n      <td>147</td>\n      <td>4.101537</td>\n      <td>14</td>\n      <td>4.318021</td>\n      <td>20.214286</td>\n      <td>78</td>\n      <td>53</td>\n      <td>32</td>\n      <td>19</td>\n      <td>2</td>\n      <td>147</td>\n      <td>1</td>\n      <td>14</td>\n      <td>52</td>\n      <td>14</td>\n      <td>86</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2510</td>\n      <td>530</td>\n      <td>232</td>\n      <td>4.798096</td>\n      <td>27</td>\n      <td>4.735849</td>\n      <td>19.629630</td>\n      <td>169</td>\n      <td>128</td>\n      <td>84</td>\n      <td>52</td>\n      <td>27</td>\n      <td>228</td>\n      <td>1</td>\n      <td>27</td>\n      <td>82</td>\n      <td>28</td>\n      <td>197</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2046</td>\n      <td>473</td>\n      <td>200</td>\n      <td>4.663535</td>\n      <td>30</td>\n      <td>4.325581</td>\n      <td>15.766667</td>\n      <td>128</td>\n      <td>87</td>\n      <td>57</td>\n      <td>34</td>\n      <td>11</td>\n      <td>249</td>\n      <td>0</td>\n      <td>30</td>\n      <td>85</td>\n      <td>36</td>\n      <td>116</td>\n      <td>31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# Features for essay\n",
    "print(len(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    0\n1   8\n2   9\n3   7\n4  10\n5   8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "# Score labels\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12976\n"
    }
   ],
   "source": [
    "X_basic = X[feature_keys_list]\n",
    "X_basic.head()\n",
    "print(len(X_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on features using linear regression\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "\n",
    "\n",
    "def evaluate(X, y):\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    #Simple K-Fold cross validation. 5 folds.\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    cv = kf.split(X)\n",
    "    results = []\n",
    "\n",
    "    for traincv, testcv in cv:\n",
    "            X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "                                        \n",
    "            model.fit(X_train,y_train)\n",
    "            start = time()\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = [item for sublist in y_pred for item in sublist]\n",
    "            y_pred = np.around(y_pred, decimals=0).astype(int)\n",
    "            y_test = [item for sublist in y_test.values for item in sublist]\n",
    "            \n",
    "            end = time()\n",
    "    \n",
    "            result = kappa(y_test,y_pred,labels=None, weights='quadratic')\n",
    "            results.append(result)\n",
    "        \n",
    "    return (np.array(results).mean())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Evaluation using basic 11 features\nKappa Score (all essays): 0.7451946428948097\n"
    }
   ],
   "source": [
    "# Using all data set\n",
    "np.random.seed(1)\n",
    "print(\"Evaluation using basic 11 features\")\n",
    "k = evaluate(X_basic, y)\n",
    "print(\"Kappa Score (all essays):\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Evaluation using all features\nKappa Score (all essays): 0.8177840358251901\n"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(\"Evaluation using all features\")\n",
    "k = evaluate(X, y)\n",
    "print(\"Kappa Score (all essays):\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set_list = []\n",
    "y_set_list = []\n",
    "essay_sets = [set1, set2, set3, set4, set5, set6, set7, set8]\n",
    "for set_no in range(8):\n",
    "    X_set, y_set = makeDataFrame(essay_sets[set_no])\n",
    "        X_set_list.append(X_set)\n",
    "            y_set_list.append(y_set) = makeDataFrame(essay_sets[set_no])\n",
    "    X_set_list.append(X_set)\n",
    "    y_set_list.append(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training sets on basic 11 features\nKappa Score for Set 1 : 0.8331024981343134\nKappa Score for Set 2 : 0.6873643522701277\nKappa Score for Set 3 : 0.6521253626079226\nKappa Score for Set 4 : 0.6877399928079586\nKappa Score for Set 5 : 0.7846507383076862\nKappa Score for Set 6 : 0.6736451029505887\nKappa Score for Set 7 : 0.7312752459645284\nKappa Score for Set 8 : 0.71497255413149\n"
    }
   ],
   "source": [
    "# Training on individual dataset\n",
    "np.random.seed(1)\n",
    "print(\"Training sets on basic 11 features\")\n",
    "for set_no in range(8):\n",
    "    X_basic_set, y_set = X_set_list[set_no][feature_keys_list], y_set_list[set_no]\n",
    "\n",
    "    print(\"Kappa Score for Set\", (set_no+1), \":\", evaluate(X_basic_set, y_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training sets on all features\nKappa Score for Set 1 : 0.8376629910072593\nKappa Score for Set 2 : 0.6966326483543922\nKappa Score for Set 3 : 0.6474088562447882\nKappa Score for Set 4 : 0.6905195626681292\nKappa Score for Set 5 : 0.7828540979457402\nKappa Score for Set 6 : 0.6869831202604875\nKappa Score for Set 7 : 0.7731733283327601\nKappa Score for Set 8 : 0.7178710463754013\n"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(\"Training sets on all features\")\n",
    "for set_no in range(8):\n",
    "    X_set, y_set = X_set_list[set_no], y_set_list[set_no]\n",
    "    print(\"Kappa Score for Set\", (set_no+1), \":\", evaluate(X_set, y_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean of features:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "char_count              952.516954\nword_count              225.458154\ndiff_words_count        108.591862\nword_count_root           3.666353\nsen_count                12.716091\navg_word_len              4.236917\navg_sen_len              20.565670\nl5_word_count            53.798166\nl6_word_count            35.832306\nl7_word_count            21.270962\nl8_word_count            11.555256\nspelling_error_count      4.819744\nstopwords_count         118.090244\nsmall_sentence_count      0.437962\npunctuations_count       13.717787\nverbs_count              36.444436\nadverbs_count            13.360897\nnouns_count              56.080996\nadjective_count          15.469097\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "print(\"Mean of features:\")\n",
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Deviation of features:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "char_count              745.525805\nword_count              178.681107\ndiff_words_count         64.705354\nword_count_root           0.726777\nsen_count                11.151927\navg_word_len              0.355270\navg_sen_len              12.388588\nl5_word_count            43.060338\nl6_word_count            29.229100\nl7_word_count            19.037364\nl8_word_count            11.194151\nspelling_error_count      4.807119\nstopwords_count          95.585648\nsmall_sentence_count      1.364738\npunctuations_count       13.106078\nverbs_count              32.863780\nadverbs_count            13.279126\nnouns_count              44.943184\nadjective_count          13.754006\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "print(\"Deviation of features:\")\n",
    "X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}