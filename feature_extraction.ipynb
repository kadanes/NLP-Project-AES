{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sets(data):\n",
    "    essay_sets = []\n",
    "    min_scores = []\n",
    "    max_scores = []\n",
    "    for s in range(1,9):\n",
    "        essay_set = data[data[\"essay_set\"] == s]\n",
    "        essay_set.dropna(axis=1, inplace=True)\n",
    "        n, d = essay_set.shape\n",
    "        set_scores = essay_set[\"domain1_score\"]\n",
    "        print (\"Set\", s, \": Essays = \", n , \"\\t Attributes = \", d)\n",
    "        min_scores.append(set_scores.min())\n",
    "        max_scores.append(set_scores.max())\n",
    "        essay_sets.append(essay_set)\n",
    "    return (essay_sets, min_scores, max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Set 1 : Essays =  1783 \t Attributes =  6\nSet 2 : Essays =  1800 \t Attributes =  9\nSet 3 : Essays =  1726 \t Attributes =  6\nSet 4 : Essays =  1770 \t Attributes =  6\nSet 5 : Essays =  1805 \t Attributes =  6\nSet 6 : Essays =  1800 \t Attributes =  6\nSet 7 : Essays =  1569 \t Attributes =  14\nSet 8 : Essays =  723 \t Attributes =  18\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   essay_id  essay_set                                              essay  \\\n0         1          1  Dear local newspaper, I think effects computer...   \n1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n4         5          1  Dear @LOCATION1, I know having computers has a...   \n\n   domain1_score  \n0              8  \n1              9  \n2              7  \n3             10  \n4              8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>essay_set</th>\n      <th>essay</th>\n      <th>domain1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Dear local newspaper, I think effects computer...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Dear @LOCATION1, I know having computers has a...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset_path = \"./asap-aes/training_set_rel3.tsv\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "min_scores = [2, 1, 0, 0, 0, 0, 0, 0]\n",
    "max_scores = [12, 6, 3, 3, 4, 4, 30, 60]\n",
    "\n",
    "essay_sets, data_min_scores, data_max_scores = split_in_sets(data)\n",
    "set1, set2, set3, set4, set5, set6, set7, set8 = tuple(essay_sets)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "\n",
    "data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n",
    "data.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Minimum Scores:  [2, 1, 0, 0, 0, 0, 0, 0]\nMaximum Scores:  [12, 6, 3, 3, 4, 4, 30, 60]\n"
    }
   ],
   "source": [
    "print(\"Minimum Scores: \", min_scores)\n",
    "print(\"Maximum Scores: \", max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset keys\n",
    "essay_id_key = \"essay_id\"\n",
    "essay_set_key = \"essay_set\"\n",
    "essay_key = \"essay\"\n",
    "domain1_score_key = \"domain1_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature keys\n",
    "char_count_key = \"char_count\"\n",
    "word_count_key = \"word_count\"\n",
    "diff_words_key = \"diff_words\"\n",
    "diff_words_count_key = \"diff_words_count\"\n",
    "word_count_root_key = \"word_count_root\"\n",
    "sen_count_key = \"sen_count\"\n",
    "avg_word_len_key = \"avg_word_len\"\n",
    "avg_sen_len_key = \"avg_sen_len\"\n",
    "l5_word_count_key = \"l5_word_count\"\n",
    "l6_word_count_key = \"l6_word_count\"\n",
    "l7_word_count_key = \"l7_word_count\"\n",
    "l8_word_count_key = \"l8_word_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def sentence_to_word_list(sentence, remove_stopwords):\n",
    "    # Remove non letter from sentenece and stop words\n",
    "    sen_char_count = 0\n",
    "    sen_word_count = 0\n",
    "    l5_sen_word_count = 0\n",
    "    l6_sen_word_count = 0\n",
    "    l7_sen_word_count = 0\n",
    "    l8_sen_word_count = 0    \n",
    "    sen_diff_words = set()\n",
    "\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    all_words = sentence.lower().split()\n",
    "    kept_words = []\n",
    "\n",
    "    for word in all_words:\n",
    "        sen_char_count += len(word)\n",
    "        sen_word_count += 1\n",
    "        word_len = len(word)\n",
    "        if word_len > 5:\n",
    "            l5_sen_word_count += 1\n",
    "        if word_len > 6:\n",
    "            l6_sen_word_count += 1\n",
    "        if word_len > 7:\n",
    "            l7_sen_word_count += 1\n",
    "        if word_len > 8:\n",
    "            l8_sen_word_count += 1\n",
    "\n",
    "        sen_diff_words.add(word)\n",
    "\n",
    "        if remove_stopwords and word not in stops:\n",
    "            kept_words.append(word)\n",
    "        else:\n",
    "            kept_words.append(word)\n",
    "\n",
    "    features = {\n",
    "         char_count_key: sen_char_count,\n",
    "         word_count_key: sen_word_count,\n",
    "         l5_word_count_key: l5_sen_word_count,\n",
    "         l6_word_count_key: l6_sen_word_count,\n",
    "         l7_word_count_key: l7_sen_word_count,\n",
    "         l8_word_count_key: l8_sen_word_count,\n",
    "         diff_words_key: sen_diff_words\n",
    "    }\n",
    "\n",
    "    return (kept_words, features)\n",
    "\n",
    "def essay_to_sentences(essay, remove_stopwords = False):\n",
    "    # Convert essay into sentence\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(essay.strip())\n",
    "    split_sentences = []\n",
    "\n",
    "    char_count = 0\n",
    "    word_count = 0\n",
    "    diff_words = set()\n",
    "    word_count_root = 0\n",
    "    sen_count = 0\n",
    "    avg_word_len = 0\n",
    "    avg_sen_len = 0\n",
    "    l5_word_count = 0\n",
    "    l6_word_count = 0\n",
    "    l7_word_count = 0\n",
    "    l8_word_count = 0    \n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            \n",
    "            kept_words, features = sentence_to_word_list(sentence, remove_stopwords)\n",
    "            split_sentences.append(kept_words)\n",
    "            \n",
    "            sen_count +=1\n",
    "            char_count += features[char_count_key]\n",
    "            word_count += features[word_count_key]\n",
    "            l5_word_count += features[l5_word_count_key]\n",
    "            l6_word_count += features[l6_word_count_key]\n",
    "            l7_word_count += features[l7_word_count_key]\n",
    "            l8_word_count += features[l8_word_count_key]\n",
    "            diff_words = diff_words|features[diff_words_key]\n",
    "\n",
    "    word_count_root = word_count ** (1/4)\n",
    "    avg_word_len = char_count / word_count\n",
    "    avg_sen_len = word_count / sen_count\n",
    "\n",
    "    features = {\n",
    "        char_count_key: char_count,\n",
    "        word_count_key: word_count,\n",
    "        diff_words_count_key: len(diff_words),\n",
    "        word_count_root_key: word_count_root,\n",
    "        sen_count_key: sen_count,\n",
    "        avg_word_len_key: avg_word_len,\n",
    "        avg_sen_len_key: avg_sen_len,\n",
    "        l5_word_count_key: l5_word_count,\n",
    "        l6_word_count_key: l6_word_count,\n",
    "        l7_word_count_key: l7_word_count,\n",
    "        l8_word_count_key: l8_word_count\n",
    "\n",
    "    }\n",
    "\n",
    "    return (split_sentences, features)\n",
    "\n",
    "\n",
    "    \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n\n\nFeatures: \n{   'avg_sen_len': 21.875,\n    'avg_word_len': 4.222857142857142,\n    'char_count': 1478,\n    'diff_words_count': 164,\n    'l5_word_count': 74,\n    'l6_word_count': 59,\n    'l7_word_count': 34,\n    'l8_word_count': 13,\n    'sen_count': 16,\n    'word_count': 350,\n    'word_count_root': 4.3253077270721105}\n"
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "#Featrues\n",
    "first_essay = data.iloc[0][essay_key]\n",
    "print(first_essay)\n",
    "split_sentences, features = essay_to_sentences(first_essay)\n",
    "# print(split_sentences)\n",
    "print(\"\\n\\nFeatures: \")\n",
    "pp.pprint(features)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def makeDataFrame(data):\n",
    "    all_features = {}\n",
    "    all_scores = {}\n",
    "\n",
    "    for row in range(len(data)):\n",
    "        essay_data = data.iloc[row]\n",
    "        essay = essay_data[essay_key]\n",
    "        essay_id = essay_data[essay_id_key]\n",
    "        essay_score = essay_data[domain1_score_key]\n",
    "        _, features = essay_to_sentences(essay)\n",
    "\n",
    "        all_features[essay_id] = features\n",
    "        all_scores[essay_id] = essay_score\n",
    "\n",
    "    X = pd.DataFrame.from_dict(all_features, orient=\"index\")\n",
    "    y = pd.DataFrame.from_dict(all_scores, orient=\"index\")\n",
    "\n",
    "    return(X, y)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = makeDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   char_count  word_count  diff_words_count  word_count_root  sen_count  \\\n1        1478         350               164         4.325308         16   \n2        1814         423               192         4.535081         20   \n3        1222         283               147         4.101537         14   \n4        2510         530               232         4.798096         27   \n5        2046         473               200         4.663535         30   \n\n   avg_word_len  avg_sen_len  l5_word_count  l6_word_count  l7_word_count  \\\n1      4.222857    21.875000             74             59             34   \n2      4.288416    21.150000            106             80             53   \n3      4.318021    20.214286             78             53             32   \n4      4.735849    19.629630            169            128             84   \n5      4.325581    15.766667            128             87             57   \n\n   l8_word_count  \n1             13  \n2             26  \n3             19  \n4             52  \n5             34  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>diff_words_count</th>\n      <th>word_count_root</th>\n      <th>sen_count</th>\n      <th>avg_word_len</th>\n      <th>avg_sen_len</th>\n      <th>l5_word_count</th>\n      <th>l6_word_count</th>\n      <th>l7_word_count</th>\n      <th>l8_word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1478</td>\n      <td>350</td>\n      <td>164</td>\n      <td>4.325308</td>\n      <td>16</td>\n      <td>4.222857</td>\n      <td>21.875000</td>\n      <td>74</td>\n      <td>59</td>\n      <td>34</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1814</td>\n      <td>423</td>\n      <td>192</td>\n      <td>4.535081</td>\n      <td>20</td>\n      <td>4.288416</td>\n      <td>21.150000</td>\n      <td>106</td>\n      <td>80</td>\n      <td>53</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1222</td>\n      <td>283</td>\n      <td>147</td>\n      <td>4.101537</td>\n      <td>14</td>\n      <td>4.318021</td>\n      <td>20.214286</td>\n      <td>78</td>\n      <td>53</td>\n      <td>32</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2510</td>\n      <td>530</td>\n      <td>232</td>\n      <td>4.798096</td>\n      <td>27</td>\n      <td>4.735849</td>\n      <td>19.629630</td>\n      <td>169</td>\n      <td>128</td>\n      <td>84</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2046</td>\n      <td>473</td>\n      <td>200</td>\n      <td>4.663535</td>\n      <td>30</td>\n      <td>4.325581</td>\n      <td>15.766667</td>\n      <td>128</td>\n      <td>87</td>\n      <td>57</td>\n      <td>34</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Features for essay\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    0\n1   8\n2   9\n3   7\n4  10\n5   8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Score labels\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on features using linear regression\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "\n",
    "\n",
    "def evaluate(X, y):\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    #Simple K-Fold cross validation. 5 folds.\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    cv = kf.split(X)\n",
    "    results = []\n",
    "\n",
    "    for traincv, testcv in cv:\n",
    "            X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "                                        \n",
    "            model.fit(X_train,y_train)\n",
    "            start = time()\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred = [item for sublist in y_pred for item in sublist]\n",
    "            y_pred = np.around(y_pred, decimals=0).astype(int)\n",
    "            y_test = [item for sublist in y_test.values for item in sublist]\n",
    "            \n",
    "            end = time()\n",
    "    \n",
    "            result = kappa(y_test,y_pred,labels=None, weights='quadratic')\n",
    "            results.append(result)\n",
    "        \n",
    "    return (np.array(results).mean())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Kappa Score (all essays): 0.7131329323591815\n"
    }
   ],
   "source": [
    "# Using all data set\n",
    "k = evaluate(X, y)\n",
    "print(\"Kappa Score (all essays):\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Kappa Score for Set 1 : 0.8353593013982256\nKappa Score for Set 2 : 0.6916456695224225\nKappa Score for Set 3 : 0.6474258307674094\nKappa Score for Set 4 : 0.6901528492942017\nKappa Score for Set 5 : 0.7809588719005301\nKappa Score for Set 6 : 0.6711635771187462\nKappa Score for Set 7 : 0.7346984316320987\nKappa Score for Set 8 : 0.7148124395252269\n"
    }
   ],
   "source": [
    "# Training on individual dataset\n",
    "essay_sets = [set1, set2, set3, set4, set5, set6, set7, set8]\n",
    "for set_no in range(8):\n",
    "    X, y = makeDataFrame(essay_sets[set_no])\n",
    "    print(\"Kappa Score for Set\", (set_no+1), \":\", evaluate(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}