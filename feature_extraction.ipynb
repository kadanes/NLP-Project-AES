{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sets(data):\n",
    "    essay_sets = []\n",
    "    min_scores = []\n",
    "    max_scores = []\n",
    "    for s in range(1,9):\n",
    "        essay_set = data[data[\"essay_set\"] == s]\n",
    "        essay_set.dropna(axis=1, inplace=True)\n",
    "        n, d = essay_set.shape\n",
    "        set_scores = essay_set[\"domain1_score\"]\n",
    "        print (\"Set\", s, \": Essays = \", n , \"\\t Attributes = \", d)\n",
    "        min_scores.append(set_scores.min())\n",
    "        max_scores.append(set_scores.max())\n",
    "        essay_sets.append(essay_set)\n",
    "    return (essay_sets, min_scores, max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Set 1 : Essays =  1783 \t Attributes =  6\nSet 2 : Essays =  1800 \t Attributes =  9\nSet 3 : Essays =  1726 \t Attributes =  6\nSet 4 : Essays =  1770 \t Attributes =  6\nSet 5 : Essays =  1805 \t Attributes =  6\nSet 6 : Essays =  1800 \t Attributes =  6\nSet 7 : Essays =  1569 \t Attributes =  14\nSet 8 : Essays =  723 \t Attributes =  18\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   essay_id  essay_set                                              essay  \\\n0         1          1  Dear local newspaper, I think effects computer...   \n1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n4         5          1  Dear @LOCATION1, I know having computers has a...   \n\n   domain1_score  \n0              8  \n1              9  \n2              7  \n3             10  \n4              8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>essay_set</th>\n      <th>essay</th>\n      <th>domain1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Dear local newspaper, I think effects computer...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Dear @LOCATION1, I know having computers has a...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "dataset_path = \"./asap-aes/training_set_rel3.tsv\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "essay_sets, min_scores, max_scores = split_in_sets(data)\n",
    "set1, set2, set3, set4, set5, set6, set7, set8 = tuple(essay_sets)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "\n",
    "data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n",
    "data.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Minimum Scores:  [2, 1, 0, 0, 0, 0, 2, 10]\nMaximum Scores:  [12, 6, 3, 3, 4, 4, 24, 60]\n"
    }
   ],
   "source": [
    "print(\"Minimum Scores: \", min_scores)\n",
    "print(\"Maximum Scores: \", max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_id_key = \"essay_id\"\n",
    "essay_set_key = \"essay_set\"\n",
    "essay_key = \"essay\"\n",
    "domain1_score_key = \"domain1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature keys\n",
    "char_count_key = \"char_count\"\n",
    "word_count_key = \"word_count\"\n",
    "diff_words_key = \"diff_words\"\n",
    "diff_words_count_key = \"diff_words_count\"\n",
    "word_count_root_key = \"word_count_root\"\n",
    "sen_count_key = \"sen_count\"\n",
    "avg_word_len_key = \"avg_word_len\"\n",
    "avg_sen_len_key = \"avg_sen_len\"\n",
    "l5_word_count_key = \"l5_word_count\"\n",
    "l6_word_count_key = \"l6_word_count\"\n",
    "l7_word_count_key = \"l7_word_count\"\n",
    "l8_word_count_key = \"l8_word_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def sentence_to_word_list(sentence, remove_stopwords):\n",
    "    # Remove non letter from sentenece and stop words\n",
    "    sen_char_count = 0\n",
    "    sen_word_count = 0\n",
    "    l5_sen_word_count = 0\n",
    "    l6_sen_word_count = 0\n",
    "    l7_sen_word_count = 0\n",
    "    l8_sen_word_count = 0    \n",
    "    sen_diff_words = set()\n",
    "\n",
    "\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    all_words = sentence.lower().split()\n",
    "    kept_words = []\n",
    "\n",
    "    for word in all_words:\n",
    "        sen_char_count += len(word)\n",
    "        sen_word_count += 1\n",
    "        word_len = len(word)\n",
    "        if word_len > 5:\n",
    "            l5_sen_word_count += 1\n",
    "        if word_len > 6:\n",
    "            l6_sen_word_count += 1\n",
    "        if word_len > 7:\n",
    "            l7_sen_word_count += 1\n",
    "        if word_len > 8:\n",
    "            l8_sen_word_count += 1\n",
    "\n",
    "        sen_diff_words.add(word)\n",
    "\n",
    "        if remove_stopwords and word not in stops:\n",
    "            kept_words.append(word)\n",
    "        else:\n",
    "            kept_words.append(word)\n",
    "\n",
    "    features = {\n",
    "         char_count_key: sen_char_count,\n",
    "         word_count_key: sen_word_count,\n",
    "         l5_word_count_key: l5_sen_word_count,\n",
    "         l6_word_count_key: l6_sen_word_count,\n",
    "         l7_word_count_key: l7_sen_word_count,\n",
    "         l8_word_count_key: l8_sen_word_count,\n",
    "         diff_words_key: sen_diff_words\n",
    "    }\n",
    "\n",
    "    return (kept_words, features)\n",
    "\n",
    "def essay_to_sentences(essay, remove_stopwords = False):\n",
    "    # Convert essay into sentence\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(essay.strip())\n",
    "    split_sentences = []\n",
    "\n",
    "    char_count = 0\n",
    "    word_count = 0\n",
    "    diff_words = set()\n",
    "    word_count_root = 0\n",
    "    sen_count = 0\n",
    "    avg_word_len = 0\n",
    "    avg_sen_len = 0\n",
    "    l5_word_count = 0\n",
    "    l6_word_count = 0\n",
    "    l7_word_count = 0\n",
    "    l8_word_count = 0    \n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0:\n",
    "            \n",
    "            kept_words, features = sentence_to_word_list(sentence, remove_stopwords)\n",
    "            split_sentences.append(kept_words)\n",
    "            \n",
    "            sen_count +=1\n",
    "            char_count += features[char_count_key]\n",
    "            word_count += features[word_count_key]\n",
    "            l5_word_count += features[l5_word_count_key]\n",
    "            l6_word_count += features[l6_word_count_key]\n",
    "            l7_word_count += features[l7_word_count_key]\n",
    "            l8_word_count += features[l8_word_count_key]\n",
    "            diff_words = diff_words|features[diff_words_key]\n",
    "\n",
    "    word_count_root = word_count ** (1/4)\n",
    "    avg_word_len = char_count / word_count\n",
    "    avg_sen_len = word_count / sen_count\n",
    "\n",
    "    features = {\n",
    "        char_count_key: char_count,\n",
    "        word_count_key: word_count,\n",
    "        diff_words_count_key: len(diff_words),\n",
    "        word_count_root_key: word_count_root,\n",
    "        sen_count_key: sen_count,\n",
    "        avg_word_len_key: avg_word_len,\n",
    "        avg_sen_len_key: avg_sen_len,\n",
    "        l5_word_count_key: l5_word_count,\n",
    "        l6_word_count_key: l6_word_count,\n",
    "        l7_word_count_key: l7_word_count,\n",
    "        l8_word_count_key: l8_word_count\n",
    "\n",
    "    }\n",
    "\n",
    "    return (split_sentences, features)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n\n\nFeatures: \n{   'avg_sen_len': 21.875,\n    'avg_word_len': 4.222857142857142,\n    'char_count': 1478,\n    'diff_words_count': 164,\n    'l5_word_count': 74,\n    'l6_word_count': 59,\n    'l7_word_count': 34,\n    'l8_word_count': 13,\n    'sen_count': 16,\n    'word_count': 350,\n    'word_count_root': 4.3253077270721105}\n"
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "#Featrues\n",
    "first_essay = data.iloc[0][essay_key]\n",
    "print(first_essay)\n",
    "split_sentences, features = essay_to_sentences(first_essay)\n",
    "# print(split_sentences)\n",
    "print(\"\\n\\nFeatures: \")\n",
    "pp.pprint(features)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}