{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOIlOlmbd6n3",
        "colab_type": "text"
      },
      "source": [
        "Load requirements.py, visualize.py, preprocess.py, feature_extraction.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6cde43y3kA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "e618ed2f-0256-485f-aedb-611f57adcf78"
      },
      "source": [
        "!pip install pyphen\n",
        "from requirements import *\n",
        "from visualize import *\n",
        "from preprocess import *\n",
        "from feature_extraction import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (0.9.5)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSW9q5bgUR1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(stopwords):\n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  default_pattern =  r\"\"\"(?x)                  \n",
        "                        (?:[A-Z]\\.)+          \n",
        "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
        "                        |\\w+(?:[-']\\w+)*      \n",
        "                    \"\"\"\n",
        "  with open('train.json') as json_file:\n",
        "      data = json.load(json_file)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieWQP4oZ3gxT",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset**\n",
        "Load train.json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o44Iiuji3Ph4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = preprocess(stopwords)\n",
        "essays, age, original_data, age_label = prepare_age(data, 0, [], [], [], [])\n",
        "essays, age, original_data, age_label = prepare_age(data, 40000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 80000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 120000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 160000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 200000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 240000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 280000, essays, age, original_data, age_label)\n",
        "essays, age, original_data, age_label = prepare_age(data, 320000, essays, age, original_data, age_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wveMBgxp5XdU",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset summary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT8KBnOu5ZWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e978d20c-a579-469b-d748-73ebbd1d0d2a"
      },
      "source": [
        "c13, c14, c15, c16, c1, c2 = age_summary(essays, age, age_label, 0, 0, 0, 0, 0, 0)\n",
        "print('Number of entries', len(age))\n",
        "\n",
        "print('13', c13, 'Percent of data', c13/len(age))\n",
        "print('14', c14, 'Percent of data', c14/len(age))\n",
        "print('15', c15, 'Percent of data', c15/len(age))\n",
        "print('16', c16, 'Percent of data', c16/len(age))\n",
        "print('\\n')\n",
        "\n",
        "print('13-14', c1, 'Percent of data', c1/len(age_label))\n",
        "print('15-16', c2, 'Percent of data', c2/len(age_label))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries 79997\n",
            "13 7211 Percent of data 0.09014088028301061\n",
            "14 14496 Percent of data 0.18120679525482206\n",
            "15 21220 Percent of data 0.2652599472480218\n",
            "16 37070 Percent of data 0.46339237721414556\n",
            "\n",
            "\n",
            "13-14 21707 Percent of data 0.2713476755378327\n",
            "15-16 58290 Percent of data 0.7286523244621673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEm2IGlm516x",
        "colab_type": "text"
      },
      "source": [
        "# **Using POS features:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX0MJiZFV0xz",
        "colab_type": "code",
        "outputId": "c1c6fe4b-63e7-407a-cb33-ba430979b125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "###------SVM WITH POS_FEATURES-------\n",
        "import sklearn\n",
        "\n",
        "\n",
        "classifier = OneVsRestClassifier(SVC(class_weight={0: 2, 1:1}))\n",
        "batches = [0,40000,80000,120000,160000,200000,240000,280000,320000]\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data, i, [], [], [], [])\n",
        "\n",
        "  pos_features = POS(essays)\n",
        "  length = len(essays)\n",
        "  trainlength = round(0.8*length)\n",
        "  features = pos_features\n",
        "  Xtrain = np.asarray(features[:trainlength])\n",
        "  Ytrain = np.asarray(age_label[:trainlength])\n",
        "\n",
        "  classifier.fit(Xtrain, Ytrain)\n",
        "#Xtrain = Xtrain.reshape(-1, 1)\n",
        "\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "#Xtest = Xtest.reshape(-1, 1)\n",
        "\n",
        "  pred = classifier.predict(Xtest)\n",
        "  acc += accuracy_score(Ytest, pred)\n",
        "\n",
        "  print('Batch', batches.index(i), ':',accuracy_score(Ytest, pred))\n",
        "print('Overall accuracy:', acc/len(batches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.7374517374517374\n",
            "Batch 1 : 0.7269662921348314\n",
            "Batch 2 : 0.7342419080068143\n",
            "Batch 3 : 0.7471655328798186\n",
            "Batch 4 : 0.7403409090909091\n",
            "Batch 5 : 0.7379619260918253\n",
            "Batch 6 : 0.7283398546674119\n",
            "Batch 7 : 0.7323462414578588\n",
            "Batch 8 : 0.7139664804469273\n",
            "Overall accuracy: 0.733197875803126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca42a2ed-ffaf-4088-8cb0-03340843baed",
        "id": "woqRLzGh59x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "###-----KNN WITH POS_FEATURES---------\n",
        "\n",
        "clf = neighbors.KNeighborsClassifier(75)\n",
        "\n",
        "batches = [0,40000,80000,120000,160000,200000,240000,280000,320000]\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data, i, [], [], [], [])\n",
        "  pos_features = POS(essays)\n",
        "  length = len(pos_features)\n",
        "  trainlength = round(0.8*length)\n",
        "  features = pos_features\n",
        "  Xtrain = np.asarray(features[:trainlength])\n",
        "  Ytrain = np.asarray(age_label[:trainlength])\n",
        "\n",
        "  clf.fit(Xtrain, Ytrain)\n",
        "\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "#Xtest = Xtest.reshape(-1, 1)\n",
        "\n",
        "  pred = clf.predict(Xtest)\n",
        "  acc += accuracy_score(Ytest, pred)\n",
        "  print('Batch', batches.index(i), ':', accuracy_score(Ytest, pred))\n",
        "print('Overall accuracy:', acc/len(batches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.7402095973524545\n",
            "Batch 1 : 0.7331460674157303\n",
            "Batch 2 : 0.7421919363997729\n",
            "Batch 3 : 0.7477324263038548\n",
            "Batch 4 : 0.740909090909091\n",
            "Batch 5 : 0.7474804031354984\n",
            "Batch 6 : 0.7361654555617664\n",
            "Batch 7 : 0.7329157175398633\n",
            "Batch 8 : 0.7212290502793296\n",
            "Overall accuracy: 0.7379977494330402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNzcFFiPRadR",
        "colab_type": "code",
        "outputId": "495f2cbf-dd6f-4c60-9a2b-6cb54c3a979e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "###-----LINEAR REGRESSION WITH POS_FEATURES---------\n",
        "\n",
        "clf = LinearRegression()\n",
        "\n",
        "batches = [0,40000,80000,120000,160000,200000,240000,280000,320000]\n",
        "mse = 0\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data, i, [], [], [], [])\n",
        "  pos_features = POS(essays)\n",
        "  length = len(pos_features)\n",
        "  trainlength = round(0.8*length)\n",
        "  features = pos_features\n",
        "  Xtrain = np.asarray(features[:trainlength])\n",
        "  Ytrain = np.asarray(age_label[:trainlength])\n",
        "\n",
        "  clf.fit(Xtrain, Ytrain)\n",
        "\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "#Xtest = Xtest.reshape(-1, 1)\n",
        "\n",
        "  pred = clf.predict(Xtest)\n",
        "  c_pred = np.round(pred)\n",
        "  mse += mean_squared_error(Ytest, pred)\n",
        "  acc += accuracy_score(Ytest, c_pred)\n",
        "  print('Batch', batches.index(i), ':', mean_squared_error(Ytest, pred), 'accuracy:', accuracy_score(Ytest, c_pred))\n",
        "print('Overall mean squared error:', mse/len(batches))\n",
        "print('Overall accuracy:', acc/len(batches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.19065496646321303 accuracy: 0.7402095973524545\n",
            "Batch 1 : 0.19725587550564172 accuracy: 0.7292134831460674\n",
            "Batch 2 : 0.18986803600452878 accuracy: 0.7427597955706985\n",
            "Batch 3 : 0.1866866518154498 accuracy: 0.7477324263038548\n",
            "Batch 4 : 0.19271158193736018 accuracy: 0.7397727272727272\n",
            "Batch 5 : 0.18899030530527478 accuracy: 0.7458006718924972\n",
            "Batch 6 : 0.19623009295556926 accuracy: 0.7350475125768586\n",
            "Batch 7 : 0.19623277399256908 accuracy: 0.7323462414578588\n",
            "Batch 8 : 0.20006606474384173 accuracy: 0.7195530726256983\n",
            "Overall mean squared error: 0.19318848319149426\n",
            "Overall accuracy: 0.7369372809109686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6t82ReUTrfT",
        "colab_type": "code",
        "outputId": "41ee2dd2-33df-44a1-bbeb-3a1ba13be74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "###---------RANDOM FOREST CLASSIFIER-----------\n",
        "clf = RandomForestClassifier(n_estimators=4, max_depth=5)\n",
        "\n",
        "batches = [0,40000,80000,120000,160000,200000,240000,280000,320000]\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data,i, [], [], [], [])\n",
        "  pos_features = POS(essays)\n",
        "  length = len(pos_features)\n",
        "  trainlength = round(0.8*length)\n",
        "  features = pos_features\n",
        "  Xtrain = np.asarray(features[:trainlength])\n",
        "  Ytrain = np.asarray(age_label[:trainlength])\n",
        "\n",
        "  clf.fit(Xtrain, Ytrain)\n",
        "\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "#Xtest = Xtest.reshape(-1, 1)\n",
        "\n",
        "  pred = clf.predict(Xtest)\n",
        "  acc += accuracy_score(Ytest, pred)\n",
        "  print('Batch', batches.index(i), ':', accuracy_score(Ytest, pred))\n",
        "print('Overall accuracy:', acc/len(batches))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.7391064533921676\n",
            "Batch 1 : 0.7286516853932584\n",
            "Batch 2 : 0.7433276547416241\n",
            "Batch 3 : 0.7477324263038548\n",
            "Batch 4 : 0.7403409090909091\n",
            "Batch 5 : 0.7446808510638298\n",
            "Batch 6 : 0.7361654555617664\n",
            "Batch 7 : 0.7317767653758542\n",
            "Batch 8 : 0.7201117318435755\n",
            "Overall accuracy: 0.73687710364076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqn0EXVO60sS",
        "colab_type": "text"
      },
      "source": [
        "# **Using n-grams:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNEVLHtFZRUL",
        "colab_type": "code",
        "outputId": "83130d9b-416f-4c91-c65a-864486650fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "###---------ORIGINAL NGRAMS WITH NAIVE BAYES------------\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "batches = []\n",
        "for i in range(100):\n",
        "  batches.append(i*1000)\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data, i, [], [], [], [])\n",
        "  trainlength = round(0.8*len(essays))\n",
        "  features = original_data\n",
        "\n",
        "  Xtrain = np.asarray(features[0:trainlength])\n",
        "  Ytrain = np.asarray(age_label[0:trainlength])\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "  if i == 0:\n",
        "    train_data, model = ngram_train(Xtrain, 1 , []) \n",
        "  else:\n",
        "    train_data, model = ngram_train(Xtrain, 1, model)\n",
        "  test_data = ngram_test(Xtest, model)\n",
        "\n",
        "  nb_classifier.fit(train_data, Ytrain)\n",
        "  pred = nb_classifier.predict(test_data)\n",
        "\n",
        "  acc += accuracy_score(Ytest, pred)\n",
        "  print('Batch',batches.index(i),':',accuracy_score(Ytest, pred))\n",
        "print('Overall accuracy:',acc/len(batches))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.7578599007170436\n",
            "Batch 1 : 0.7575757575757576\n",
            "Batch 2 : 0.7588300220750552\n",
            "Batch 3 : 0.7527593818984547\n",
            "Batch 4 : 0.7615894039735099\n",
            "Batch 5 : 0.7545706371191135\n",
            "Batch 6 : 0.7512520868113522\n",
            "Batch 7 : 0.7426183844011142\n",
            "Batch 8 : 0.7399777282850779\n",
            "Batch 9 : 0.7324805339265851\n",
            "Batch 10 : 0.7259052924791086\n",
            "Batch 11 : 0.7324022346368715\n",
            "Batch 12 : 0.7292015633724176\n",
            "Batch 13 : 0.7329988851727982\n",
            "Batch 14 : 0.7384529771841959\n",
            "Batch 15 : 0.7433333333333333\n",
            "Batch 16 : 0.7357340720221607\n",
            "Batch 17 : 0.745141588006663\n",
            "Batch 18 : 0.7386237513873474\n",
            "Batch 19 : 0.7465258476931629\n",
            "Batch 20 : 0.7401443642420877\n",
            "Batch 21 : 0.733222407099279\n",
            "Batch 22 : 0.7258601553829079\n",
            "Batch 23 : 0.7288888888888889\n",
            "Batch 24 : 0.7332962138084632\n",
            "Batch 25 : 0.7316258351893096\n",
            "Batch 26 : 0.7423312883435583\n",
            "Batch 27 : 0.7434613244296049\n",
            "Batch 28 : 0.7484696716750139\n",
            "Batch 29 : 0.7427616926503341\n",
            "Batch 30 : 0.7497206703910615\n",
            "Batch 31 : 0.7388392857142857\n",
            "Batch 32 : 0.7371651785714286\n",
            "Batch 33 : 0.7371364653243848\n",
            "Batch 34 : 0.738521836506159\n",
            "Batch 35 : 0.7315848214285714\n",
            "Batch 36 : 0.7288515406162465\n",
            "Batch 37 : 0.7377877596855699\n",
            "Batch 38 : 0.7466216216216216\n",
            "Batch 39 : 0.7456387169386607\n",
            "Batch 40 : 0.7539325842696629\n",
            "Batch 41 : 0.7455056179775281\n",
            "Batch 42 : 0.7369014084507042\n",
            "Batch 43 : 0.7425183512140033\n",
            "Batch 44 : 0.7468996617812852\n",
            "Batch 45 : 0.7389830508474576\n",
            "Batch 46 : 0.732545045045045\n",
            "Batch 47 : 0.7418447694038245\n",
            "Batch 48 : 0.7383230163196398\n",
            "Batch 49 : 0.7459154929577465\n",
            "Batch 50 : 0.7431295569265284\n",
            "Batch 51 : 0.7488814317673378\n",
            "Batch 52 : 0.7452407614781635\n",
            "Batch 53 : 0.7539149888143176\n",
            "Batch 54 : 0.7477628635346756\n",
            "Batch 55 : 0.7396416573348265\n",
            "Batch 56 : 0.7487352445193929\n",
            "Batch 57 : 0.7476217123670957\n",
            "Batch 58 : 0.7566964285714286\n",
            "Batch 59 : 0.75\n",
            "Batch 60 : 0.7474804031354984\n",
            "Batch 61 : 0.7488789237668162\n",
            "Batch 62 : 0.7544742729306487\n",
            "Batch 63 : 0.7519553072625699\n",
            "Batch 64 : 0.7416481069042317\n",
            "Batch 65 : 0.7462353597322923\n",
            "Batch 66 : 0.7377232142857143\n",
            "Batch 67 : 0.7367244270542203\n",
            "Batch 68 : 0.735870173475098\n",
            "Batch 69 : 0.7366647950589557\n",
            "Batch 70 : 0.7386172006745363\n",
            "Batch 71 : 0.7395950506186727\n",
            "Batch 72 : 0.7505630630630631\n",
            "Batch 73 : 0.7473269555430501\n",
            "Batch 74 : 0.7450648618161309\n",
            "Batch 75 : 0.7422272470322216\n",
            "Batch 76 : 0.7405313736574336\n",
            "Batch 77 : 0.7402597402597403\n",
            "Batch 78 : 0.7432279909706546\n",
            "Batch 79 : 0.7361268403171007\n",
            "Batch 80 : 0.7410562180579217\n",
            "Batch 81 : 0.7362137578169414\n",
            "Batch 82 : 0.7301136363636364\n",
            "Batch 83 : 0.7306168647425014\n",
            "Batch 84 : 0.7219705549263873\n",
            "Batch 85 : 0.7288613303269448\n",
            "Batch 86 : 0.7246621621621622\n",
            "Batch 87 : 0.7251693002257337\n",
            "Batch 88 : 0.7252124645892352\n",
            "Batch 89 : 0.730221969265794\n",
            "Batch 90 : 0.7302857142857143\n",
            "Batch 91 : 0.7351258581235698\n",
            "Batch 92 : 0.7355796687607081\n",
            "Batch 93 : 0.7375643224699828\n",
            "Batch 94 : 0.7372638809387522\n",
            "Batch 95 : 0.7397025171624714\n",
            "Batch 96 : 0.7347055460263008\n",
            "Batch 97 : 0.7339816933638444\n",
            "Batch 98 : 0.7351258581235698\n",
            "Batch 99 : 0.7449856733524355\n",
            "Overall accuracy: 0.7406437106280248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6oLUtjj668v",
        "colab_type": "text"
      },
      "source": [
        "# **Using text-readability features:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av2zitpHgUby",
        "colab_type": "code",
        "outputId": "2ac4e0a3-f703-4b6e-9255-1dfc1ef80061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "###------SVM WITH PENTEL FEATURES-------http://ceur-ws.org/Vol-1446/smlir_submission2.pdf\n",
        "classifier = OneVsRestClassifier(SVC())\n",
        "batches = [0,40000,80000,120000,160000,200000,240000,280000]\n",
        "acc = 0\n",
        "for i in batches:\n",
        "  essays, age, original_data, age_label = prepare_age(data, i, [], [], [], [])\n",
        "\n",
        "  features, age_label = extract_features(essays, age_label)\n",
        "  length = len(features)\n",
        "  trainlength = round(0.8*length)\n",
        "  Xtrain = np.asarray(features[:trainlength])\n",
        "  Ytrain = np.asarray(age_label[:trainlength])\n",
        "\n",
        "  classifier.fit(Xtrain, Ytrain)\n",
        "#Xtrain = Xtrain.reshape(-1, 1)\n",
        "\n",
        "  Xtest = np.asarray(features[trainlength:])\n",
        "  Ytest = np.asarray(age_label[trainlength:])\n",
        "\n",
        "#Xtest = Xtest.reshape(-1, 1)\n",
        "\n",
        "  pred = classifier.predict(Xtest)\n",
        "\n",
        "  acc += accuracy_score(Ytest, pred)\n",
        "  print('Batch', batches.index(i), ':',accuracy_score(Ytest, pred))\n",
        "print('Overall accuracy:', acc/len(batches))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 : 0.7386489479512736\n",
            "Batch 1 : 0.7367231638418079\n",
            "Batch 2 : 0.7482876712328768\n",
            "Batch 3 : 0.7472965281730222\n",
            "Batch 4 : 0.7414383561643836\n",
            "Batch 5 : 0.7467642093415869\n",
            "Batch 6 : 0.7365168539325843\n",
            "Batch 7 : 0.7332570120206068\n",
            "Overall accuracy: 0.7411165928322677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ORxBSHZ7E6G",
        "colab_type": "text"
      },
      "source": [
        "# **Analysis on HP dataset:**\n",
        "Load training_set_rel3.tsv (in asap-aes folder) and age_pentel_model.sav"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOzbys3nYpv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "c2baf9c8-b182-458c-9cab-6181a207d329"
      },
      "source": [
        "#Parth's code\n",
        "%matplotlib inline\n",
        "\n",
        "dataset_path = \"training_set_rel3.tsv\"\n",
        "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\", index_col=\"essay_id\")\n",
        "min_scores = [2, 1, 0, 0, 0, 0, 0, 0]\n",
        "max_scores = [12, 6, 3, 3, 4, 4, 30, 60]\n",
        "\n",
        "essay_sets, data_min_scores, data_max_scores = split_in_sets(data)\n",
        "set1, set2, set3, set4, set5, set6, set7, set8 = tuple(essay_sets)\n",
        "data.dropna(axis=1, inplace=True)\n",
        "\n",
        "data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n",
        "print(\"All Data:\", len(data))\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set 1 : Essays =  1783 \t Attributes =  5\n",
            "Set 2 : Essays =  1800 \t Attributes =  8\n",
            "Set 3 : Essays =  1726 \t Attributes =  5\n",
            "Set 4 : Essays =  1770 \t Attributes =  5\n",
            "Set 5 : Essays =  1805 \t Attributes =  5\n",
            "Set 6 : Essays =  1800 \t Attributes =  5\n",
            "Set 7 : Essays =  1569 \t Attributes =  13\n",
            "Set 8 : Essays =  723 \t Attributes =  17\n",
            "All Data: 12976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/feature_extraction.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  essay_set.dropna(axis=1, inplace=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>essay_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          essay_set  ... domain1_score\n",
              "essay_id             ...              \n",
              "1                 1  ...             8\n",
              "2                 1  ...             9\n",
              "3                 1  ...             7\n",
              "4                 1  ...            10\n",
              "5                 1  ...             8\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nSG727vYtG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parth's code\n",
        "#Dataset keys\n",
        "essay_id_key = \"essay_id\"\n",
        "essay_set_key = \"essay_set\"\n",
        "essay_key = \"essay\"\n",
        "domain1_score_key = \"domain1_score\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fe18c9ad-4ae3-43e9-c8ad-25410b62c3a0",
        "id": "CdKTyeF1Yj9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "all_essays = []\n",
        "all_scores = []\n",
        "norm_score = []\n",
        "y = []\n",
        "\n",
        "classifier = pickle.load(open('age_pentel_model.sav', 'rb'))\n",
        "c1 = 0\n",
        "c2 = 0\n",
        "\n",
        "for idx in range(len(data)):\n",
        "  all_essays.append(data.iloc[idx][essay_key])\n",
        "  all_scores.append(data.iloc[idx][domain1_score_key])\n",
        "  set_id = data.iloc[idx][essay_set_key]\n",
        "  if set_id == 7 or set_id == 1 or set_id == 5: #grades 7-8\n",
        "    y.append(1)\n",
        "    c1 += 1\n",
        "  elif set_id == 2 or set_id == 3 or set_id == 4 or set_id == 6 or set_id == 8:\n",
        "    y.append(2)\n",
        "    c2 += 1\n",
        "  sc = data.iloc[idx][domain1_score_key]\n",
        "  if set_id == 1:\n",
        "    norm_score.append(sc/12)\n",
        "  elif set_id == 2:\n",
        "    norm_score.append(sc/6)\n",
        "  elif set_id == 3 or set_id == 4:\n",
        "    norm_score.append(sc/3)\n",
        "  elif set_id == 5 or set_id == 6:\n",
        "    norm_score.append(sc/4)\n",
        "  elif set_id == 7:\n",
        "    norm_score.append(sc/30)\n",
        "  else:\n",
        "    norm_score.append(sc/60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Grade 7-8:', c1)\n",
        "print('Grade 9-10:', c2)\n",
        "\n",
        "e = prepare_test(all_essays)\n",
        "e = np.asarray(e)\n",
        "\n",
        "#e_feats = POS(e)\n",
        "e_feats = pentel_features(e)\n",
        "y = np.asarray(y)\n",
        "\n",
        "pred = classifier.predict(e_feats)\n",
        "y_pred = np.round(pred)\n",
        "print('Accuracy score on HP dataset:',accuracy_score(y, y_pred))\n",
        "\n",
        "score1 = 0\n",
        "score2 = 0\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "count3 = 0\n",
        "score3 = 0\n",
        "\n",
        "f1 = np.zeros(len(e_feats[0]))\n",
        "f2 = np.zeros(len(e_feats[0]))\n",
        "f3 = np.copy(f2)\n",
        "\n",
        "for i in range(len(e_feats)):\n",
        "  if y[i] == 1: \n",
        "    score1 += norm_score[i]\n",
        "    count1 += 1\n",
        "    f1 += e_feats[i]\n",
        "  else:\n",
        "    score2 += norm_score[i]\n",
        "    count2 += 1\n",
        "    f2 += e_feats[i]\n",
        "  if norm_score[i] > 0.8:\n",
        "    f3 += e_feats[i]\n",
        "    score3 += norm_score[i]\n",
        "    count3 += 1\n",
        "\n",
        "print('Observing bias:\\n')\n",
        "print('7-8 graders average score:', score1/count1)\n",
        "print('9-10 graders average score:', score2/count2)\n",
        "\n",
        "f1 = f1/count1\n",
        "f2 = f2/count2\n",
        "\n",
        ",\n",
        "print('\\n')\n",
        "print('Feature:                                     ', 'Avg value for 7-8 graders    ', 'Avg value for 9-10 graders')\n",
        "print('Avg no of characters in a word               ', f1[0],'                       ', f2[0])\n",
        "print('Avg no of words in an entry                  ', f1[1],'                       ', f2[1])\n",
        "print('Avg ratio of complex words to all words      ', f1[2],'                       ', f2[2])\n",
        "print('Avg number of syllables per word             ', f1[3],'                       ', f2[3])\n",
        "print('Avg ratio of 1-syllable words to all words   ', f1[4],'                       ', f2[4])\n",
        "print('Avg ratio of 2-syllable words to all words   ', f1[5],'                       ', f2[5])\n",
        "print('Avg ratio of 3-syllable words to all words   ', f1[6],'                       ', f2[6])\n",
        "print('Avg ratio of 4-syllable words to all words   ', f1[7],'                       ', f2[7])\n",
        "print('Avg ratio of 5-syllable words to all words   ', f1[8],'                       ', f2[8])\n",
        "print('Avg ratio of 6-syllable words to all words   ', f1[9],'                       ', f2[9])\n",
        "print('Avg ratio of 7-syllable words to all words   ', f1[10],'                      ', f2[10])\n",
        "print('Avg ratio of 8-syllable words to all words   ', f1[11],'                                        ', f2[11])\n",
        "\n",
        "print('\\n Average feature for a score higher than 0.8:\\n')\n",
        "f3 = f3/count3\n",
        "print('Avg no of characters in a word             ', f3[0])\n",
        "print('Avg no of words in an entry                ', f3[1])\n",
        "print('Avg ratio of complex words to all words     ', f3[2])\n",
        "print('Avg number of syllables per word            ', f3[3])\n",
        "print('Avg ratio of 1-syllable words to all words ', f3[4])\n",
        "print('Avg ratio of 2-syllable words to all words', f3[5])\n",
        "print('Avg ratio of 3-syllable words to all words', f3[6])\n",
        "print('Avg ratio of 4-syllable words to all words', f3[7])\n",
        "print('Avg ratio of 5-syllable words to all words', f3[8])\n",
        "print('Avg ratio of 6-syllable words to all words ', f3[9])\n",
        "print('Avg ratio of 7-syllable words to all words', f3[10])\n",
        "print('Avg ratio of 8-syllable words to all words', f3[11])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grade 7-8: 5157\n",
            "Grade 9-10: 7819\n",
            "Accuracy score on HP dataset: 0.6025739827373613\n",
            "Observing bias:\n",
            "\n",
            "7-8 graders average score: 0.6193975825738465\n",
            "9-10 graders average score: 0.5885982862258675\n",
            "\n",
            "\n",
            "Feature:                                      Avg value for 7-8 graders     Avg value for 9-10 graders\n",
            "Avg no of characters in a word                4.213243290946323                         4.346382762791239\n",
            "Avg no of words in an entry                   220.93368237347295                         224.85829389947563\n",
            "Avg ratio of complex words to all words       0.01207175405801296                         0.016911816334866284\n",
            "Avg number of syllables per word              0.3351132753186762                         0.3371852009780049\n",
            "Avg ratio of 1-syllable words to all words    0.1801288431016428                         0.18407552350903708\n",
            "Avg ratio of 2-syllable words to all words    0.057745837386756635                         0.05004014451095775\n",
            "Avg ratio of 3-syllable words to all words    0.00891024079408362                         0.014750883025668862\n",
            "Avg ratio of 4-syllable words to all words    0.003073361525833735                         0.002042275306007292\n",
            "Avg ratio of 5-syllable words to all words    7.53870235103724e-05                         0.00010548446695250919\n",
            "Avg ratio of 6-syllable words to all words    6.0463320887025515e-06                         1.2458991300701012e-05\n",
            "Avg ratio of 7-syllable words to all words    6.07629246782974e-06                        5.611953055720588e-07\n",
            "Avg ratio of 8-syllable words to all words    0.0                                          0.0\n",
            "\n",
            " Average feature for a score higher than 0.8:\n",
            "\n",
            "Avg no of characters in a word              4.508371301935448\n",
            "Avg no of words in an entry                 285.4650293646556\n",
            "Avg ratio of complex words to all words      0.022461642610245105\n",
            "Avg number of syllables per word             0.40204617158268846\n",
            "Avg ratio of 1-syllable words to all words  0.19002592542003335\n",
            "Avg ratio of 2-syllable words to all words 0.07013075493503657\n",
            "Avg ratio of 3-syllable words to all words 0.018311417941750792\n",
            "Avg ratio of 4-syllable words to all words 0.003958983336918563\n",
            "Avg ratio of 5-syllable words to all words 0.0001682490059253526\n",
            "Avg ratio of 6-syllable words to all words  1.556270329999636e-05\n",
            "Avg ratio of 7-syllable words to all words 6.789451091798165e-06\n",
            "Avg ratio of 8-syllable words to all words 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV5qpa7YjCiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}